{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUzKtGdQV7mi",
        "outputId": "1ee35484-0da0-4e9f-a3c0-f8877079ad0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2026.1.4)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
        "print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOdjMX6TWuio",
        "outputId": "0c8a81c6-8ad8-4d0c-a77b-96c79f47748a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'asl-alphabet' dataset.\n",
            "/kaggle/input/asl-alphabet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe==0.10.13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "opJPXgH5yPq6",
        "outputId": "f982bfcd-0fcc-41d2-cf98-70c8ee30b637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe==0.10.13\n",
            "  Downloading mediapipe-0.10.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.13) (2.3.1)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.13) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.13) (25.12.19)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.13) (0.7.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.13) (0.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.13) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.13) (2.0.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.13) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe==0.10.13)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.13) (0.5.5)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.13) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.13) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.13) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.13) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.13) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.13) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.13) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.13) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.13) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.13) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.13) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.13) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.13) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->sounddevice>=0.4.4->mediapipe==0.10.13) (2.23)\n",
            "Downloading mediapipe-0.10.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: mediapipe\n",
            "    Found existing installation: mediapipe 0.10.31\n",
            "    Uninstalling mediapipe-0.10.31:\n",
            "      Successfully uninstalled mediapipe-0.10.31\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.14.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "grain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.13 protobuf-4.25.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "a71f99ad82b04304bdf6c11171293a02"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)\n",
        "\n",
        "F = 63"
      ],
      "metadata": {
        "id": "wPZn82L_W6zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = hands.process(img)\n",
        "\n",
        "    kp = np.zeros((F,), dtype=np.float32)\n",
        "\n",
        "    if res.multi_hand_landmarks:\n",
        "        hand = res.multi_hand_landmarks[0]\n",
        "        for i, lm in enumerate(hand.landmark):\n",
        "            kp[i*3:i*3+3] = [lm.x, lm.y, lm.z]\n",
        "\n",
        "    return kp"
      ],
      "metadata": {
        "id": "XsaQMLjcW-ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "\n",
        "if os.path.exists(\"data/train\"):\n",
        "    shutil.rmtree(\"data/train\")\n",
        "\n",
        "os.makedirs(\"data/train\", exist_ok=True)"
      ],
      "metadata": {
        "id": "oyO2ldktaTCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "BASE = \"/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train\"\n",
        "MAX_PER_CLASS = 100\n",
        "\n",
        "sample_id = 0\n",
        "\n",
        "for letter in sorted(os.listdir(BASE)):\n",
        "    letter_path = os.path.join(BASE, letter)\n",
        "\n",
        "    # Only real classes: A–Z\n",
        "    if not os.path.isdir(letter_path) or len(letter) != 1:\n",
        "        continue\n",
        "\n",
        "    print(\"Processing class:\", letter)\n",
        "\n",
        "    images = os.listdir(letter_path)[:MAX_PER_CLASS]\n",
        "\n",
        "    for img in tqdm(images, leave=False):\n",
        "        img_path = os.path.join(letter_path, img)\n",
        "\n",
        "        try:\n",
        "            kp = extract_from_image(img_path)\n",
        "\n",
        "            np.save(f\"data/train/{sample_id}.npy\", kp)\n",
        "            with open(f\"data/train/{sample_id}.txt\", \"w\") as f:\n",
        "                f.write(letter)\n",
        "\n",
        "            sample_id += 1\n",
        "\n",
        "        except Exception:\n",
        "            continue\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57FR5fU5aU0Q",
        "outputId": "618c1a3e-a93b-4510-d900-0de52b7b3860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: E\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: F\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: J\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: K\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: N\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: O\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: P\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: R\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: U\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: V\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: W\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: X\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Z\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = sorted(set(\n",
        "    open(f\"data/train/{f.replace('.npy','.txt')}\").read().strip()\n",
        "    for f in os.listdir(\"data/train\") if f.endswith(\".npy\")\n",
        "))\n",
        "\n",
        "label2idx = {c: i for i, c in enumerate(labels)}\n",
        "idx2label = {i: c for c, i in label2idx.items()}\n",
        "\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "print(\"Labels:\", labels)\n",
        "print(\"NUM_CLASSES:\", NUM_CLASSES)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbZ_1KxWab-K",
        "outputId": "d2c8b4eb-1f30-43d2-b505-4f0f0330876f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
            "NUM_CLASSES: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "all_ids = [f.replace(\".npy\",\"\") for f in os.listdir(\"data/train\") if f.endswith(\".npy\")]\n",
        "\n",
        "train_ids, val_ids = train_test_split(\n",
        "    all_ids,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=[\n",
        "        open(f\"data/train/{i}.txt\").read().strip()\n",
        "        for i in all_ids\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "F-6eggj1bEb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ASLDataset(Dataset):\n",
        "    def __init__(self, root, ids):\n",
        "        self.root = root\n",
        "        self.ids = ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sid = self.ids[idx]\n",
        "        x = torch.tensor(\n",
        "            np.load(f\"{self.root}/{sid}.npy\"),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "        y = open(f\"{self.root}/{sid}.txt\").read().strip()\n",
        "        return x, label2idx[y]"
      ],
      "metadata": {
        "id": "QUwZbFvdbGzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    ASLDataset(\"data/train\", train_ids),\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    ASLDataset(\"data/train\", val_ids),\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "5dslUG45bIfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ASLClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(63, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(128, NUM_CLASSES)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "A4rLNAcPbMDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ASLClassifier().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "pG6yiyuFbOgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    total, correct = 0, 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        logits = model(x)\n",
        "        loss = loss_fn(logits, y)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total += y.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    vtotal, vcorrect = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            vtotal += y.size(0)\n",
        "            vcorrect += (logits.argmax(1) == y).sum().item()\n",
        "\n",
        "    val_acc = vcorrect / vtotal\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train={train_acc:.3f}, Val={val_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAAJOmAObREY",
        "outputId": "482c6a1f-bf1c-4241-bb3c-ae70df30180b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train=0.229, Val=0.350\n",
            "Epoch 2: Train=0.532, Val=0.598\n",
            "Epoch 3: Train=0.662, Val=0.721\n",
            "Epoch 4: Train=0.706, Val=0.687\n",
            "Epoch 5: Train=0.721, Val=0.746\n",
            "Epoch 6: Train=0.736, Val=0.760\n",
            "Epoch 7: Train=0.747, Val=0.771\n",
            "Epoch 8: Train=0.748, Val=0.777\n",
            "Epoch 9: Train=0.741, Val=0.748\n",
            "Epoch 10: Train=0.749, Val=0.783\n",
            "Epoch 11: Train=0.755, Val=0.779\n",
            "Epoch 12: Train=0.763, Val=0.771\n",
            "Epoch 13: Train=0.763, Val=0.775\n",
            "Epoch 14: Train=0.755, Val=0.767\n",
            "Epoch 15: Train=0.754, Val=0.771\n",
            "Epoch 16: Train=0.753, Val=0.769\n",
            "Epoch 17: Train=0.762, Val=0.763\n",
            "Epoch 18: Train=0.757, Val=0.765\n",
            "Epoch 19: Train=0.763, Val=0.692\n",
            "Epoch 20: Train=0.763, Val=0.748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "\n",
        "torch.save(model.state_dict(), \"asl_mlp.pth\")\n",
        "\n",
        "with open(\"label_map.json\", \"w\") as f:\n",
        "    json.dump(label2idx, f)"
      ],
      "metadata": {
        "id": "LcNUVh9PiZNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxscript\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ASrN6roicHY",
        "outputId": "d49d49d7-7ba8-4803-ea01-5c411067d28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnxscript) (2.0.2)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.15-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting onnx>=1.16 (from onnxscript)\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (4.15.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->onnxscript) (4.25.8)\n",
            "Downloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.15-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, onnx_ir, onnxscript\n",
            "Successfully installed onnx-1.20.1 onnx_ir-0.1.15 onnxscript-0.5.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "dummy_input = torch.randn(1, 63).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy_input,\n",
        "        \"asl_mlp.onnx\",\n",
        "        input_names=[\"keypoints\"],\n",
        "        output_names=[\"logits\"],\n",
        "        dynamic_axes={\n",
        "            \"keypoints\": {0: \"batch\"},\n",
        "            \"logits\": {0: \"batch\"}\n",
        "        },\n",
        "        opset_version=17\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16GEpxYPjRGF",
        "outputId": "3185bdd9-a169-4d66-c847-c85f613777da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2869588538.py:6: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W0127 19:06:26.437000 1929 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 17 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `ASLClassifier([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `ASLClassifier([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 17).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 1 of general pattern rewrite rules.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"asl_mlp.onnx\")\n",
        "files.download(\"label_map.json\")\n",
        "files.download(\"asl_mlp.onnx.data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "osE2wTcUkDXL",
        "outputId": "1c8b3da0-ce73-4e34-9d59-15487fb01f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f65f0cd5-058b-462f-acd9-c36e00ec3bae\", \"asl_mlp.onnx\", 1485)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1c0f6596-b0b3-41ab-9641-e3009ed28f8c\", \"label_map.json\", 224)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a98b668c-f7ff-43dd-961a-d117fb7273c4\", \"asl_mlp.onnx.data\", 210432)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2IJJKZn3Vss",
        "outputId": "375e071f-2e54-4ea0-dbb9-e6db3344f17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asl_mlp.onnx  asl_mlp.onnx.data  asl_mlp.pth  data  label_map.json  sample_data\n"
          ]
        }
      ]
    }
  ]
}